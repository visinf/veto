DTYPE: "float32"
MODEL:
  BALANCED_NORM: False
  PRETRAINED_DETECTOR_CKPT_VG: "/data/gsudhakaran/models/hlnet/checkpoint/model_final.pth"
  PRETRAINED_DETECTOR_CKPT_GQA: "/storage-01/ml-gsudhakaran/data/GQA/model_final_from_vg.pth"
  WEIGHT: ""
  BACKBONE:
    CONV_BODY: "R-101-FPN"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    VG_NUM_CLASSES: 151                # 151 for VG, 201 for GQA
    GQA_200_NUM_CLASSES: 201         # 151 for VG, 201 for GQA
    MLP_HEAD_DIM: 4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_BGFG_RATIO: 3
  ROI_RELATION_HEAD:
    POOLER_RESOLUTION: 8
    USE_GT_BOX: False
    USE_GT_OBJECT_LABEL: False
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: False    # for sgdet only, in case some gt boxes are missing
    VG_NUM_CLASSES: 51                 # 51 for VG, 101 for GQA (not contain "to the left of" & "to the right of")
    GQA_200_NUM_CLASSES: 101
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 128  #256 #576 #4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    FEATURE_EXTRACTOR_MINI: "VETOFeatureExtractor"
    #################### Select Relationship Model ####################
    PREDICTOR: "VETOPredictor_MEET" #"VETOPredictor"
    ############### Parameters for Transformer Predictor ##############
    VETOTRANSFORMER:
      PATCH_SIZE: 2
      T_INPUT_DIM: 576
      ENC_LAYERS: 6
      NHEADS: 6
      EMB_DROPOUT: 0.35
      T_DROPOUT: 0.35
DATASETS:
  VG_TRAIN: ("VG_stanford_filtered_with_attribute_incl_depth_train",)
  VG_VAL: ("VG_stanford_filtered_with_attribute_incl_depth_val",)
  VG_TEST: ("VG_stanford_filtered_with_attribute_incl_depth_test",)
  GQA_200_TRAIN: ("GQA_200_incl_depth_train",)
  GQA_200_VAL: ("GQA_200_incl_depth_val",)
  GQA_200_TEST: ("GQA_200_incl_depth_test",)
  USE_DEPTH: True
  USE_BIAS: True
  REORDER_FREQ_BASED: True
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BASE_LR: 0.0001
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 5000
  VAL_PERIOD: 5000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 8
  MAX_ITER: 100000 #80000
  MOMENTUM: 0.9
  PRE_VAL: false
  PRINT_GRAD_FREQ: 50000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau #WarmupMultiStepLR
  STEPS:
  - 50000
  - 90000
  - 130000
  - 160000
  TO_VAL: true
  UPDATE_SCHEDULE_DURING_LOAD: false
  #VAL_PERIOD: 4000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 3000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 1.0e-05
  WEIGHT_DECAY_BIAS: 0.0
OUTPUT_DIR: "/data/gsudhakaran/models/Ensemble/exp/VETO_context"
GLOVE_DIR: "/visinf/home/gsudhakaran/scene_graphs/HL-Net/glove"
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5
GLOBAL_SETTING:
  DATASET_CHOICE: 'VG'
  USE_BIAS: False                                      # If use the relation statistics to serve as the priori knowledge
  BETA_LOSS: True
  CHOOSE_BEST_MODEL_BY_METRIC: '_mean_recall'         # ['_recall', '_mean_recall'] To control which metric is the main concern
  PRINT_INTERVAL: 100
GCL_SETTING:
    GROUP_SPLIT_MODE: 'divide4'                       # To control the number of groups ['divide4', ''divide3', 'divide5', 'average']
    KNOWLEDGE_LOSS_COEFFICIENT: 1.0                   # To control the loss of Knowledge Transfer
    KNOWLEDGE_TRANSFER_MODE: 'KL_logit_TopDown'       # To control how to transfer the knowledge between different auxiliary classifiers
    # ['None', 'KL_logit_Neighbor', 'KL_logit_None', 'KL_logit_TopDown', 'KL_logit_BottomUp', 'KL_logit_BiDirection']
    ############### The Following Parameters would not affect the performance much, is nearly useless ##############
    NO_RELATION_RESTRAIN: True              # If two object do not have a relation, then limit their contribution to the final loss
    ZERO_LABEL_PADDING_MODE: 'rand_insert'  # ['rand_insert', 'rand_choose', 'all_include'], to control how to insert into the relation which is ZERO
    NO_RELATION_PENALTY: 0.1
ENSEMBLE_LEARNING:
  ENABLED: True
  TYPE: ['group']
  VOTING: 'C'  #'C' or 'U'
  EXPERT_GROUP: False